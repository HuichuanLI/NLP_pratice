{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huffman树的构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuffmanNode:\n",
    "    def __init__(self,word_id,frequency):\n",
    "        self.word_id = word_id\n",
    "        self.frequency = frequency\n",
    "        self.left_child = None\n",
    "        self.right_child = None\n",
    "        self.father = None\n",
    "        self.Huffman_code = []\n",
    "        self.path = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordid_frequency_dict = {0: 4, 1: 6, 2: 3, 3: 2, 4: 2}\n",
    "wordid_code = dict()\n",
    "wordid_path = dict()\n",
    "unmerge_node_list = [HuffmanNode(wordid,frequency) for wordid,frequency in wordid_frequency_dict.items()]\n",
    "huffman = [HuffmanNode(wordid,frequency) for wordid,frequency in wordid_frequency_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_node(node1,node2):\n",
    "    sum_frequency = node1.frequency + node2.frequency\n",
    "    mid_node_id = len(huffman)\n",
    "    father_node = HuffmanNode(mid_node_id, sum_frequency)\n",
    "    if node1.frequency >= node2.frequency:\n",
    "        father_node.left_child = node1\n",
    "        father_node.right_child = node2\n",
    "    else:\n",
    "        father_node.left_child = node2\n",
    "        father_node.right_child = node1\n",
    "    huffman.append(father_node)\n",
    "    return father_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node = merge_node(unmerge_node_list[0],unmerge_node_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node.frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(node_list):\n",
    "    while len(node_list) > 1:\n",
    "        i1 = 0  # 概率最小的节点\n",
    "        i2 = 1  # 概率第二小的节点\n",
    "        if node_list[i2].frequency < node_list[i1].frequency:\n",
    "            [i1, i2] = [i2, i1]\n",
    "        for i in range(2, len(node_list)):\n",
    "            if node_list[i].frequency < node_list[i2].frequency:\n",
    "                i2 = i\n",
    "                if node_list[i2].frequency < node_list[i1].frequency:\n",
    "                    [i1, i2] = [i2, i1]\n",
    "        father_node = merge_node(node_list[i1], node_list[i2])  # 合并最小的两个节点\n",
    "        if i1 < i2:\n",
    "            node_list.pop(i2)\n",
    "            node_list.pop(i1)\n",
    "        elif i1 > i2:\n",
    "            node_list.pop(i1)\n",
    "            node_list.pop(i2)\n",
    "        else:\n",
    "            raise RuntimeError('i1 should not be equal to i2')\n",
    "        node_list.insert(0, father_node)  # 插入新节点\n",
    "    root = node_list[0]\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = build_tree(unmerge_node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(huffman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_huffman_code_and_path():\n",
    "    stack = [root]\n",
    "    while len(stack) > 0:\n",
    "        node = stack.pop()\n",
    "        # 顺着左子树走\n",
    "        while node.left_child or node.right_child:\n",
    "            code = node.Huffman_code\n",
    "            path = node.path\n",
    "            node.left_child.Huffman_code = code + [1]\n",
    "            node.right_child.Huffman_code = code + [0]\n",
    "            node.left_child.path = path + [node.word_id]\n",
    "            node.right_child.path = path + [node.word_id]\n",
    "            # 把没走过的右子树加入栈\n",
    "            stack.append(node.right_child)\n",
    "            node = node.left_child\n",
    "        word_id = node.word_id\n",
    "        word_code = node.Huffman_code\n",
    "        word_path = node.path\n",
    "        huffman[word_id].Huffman_code = word_code\n",
    "        huffman[word_id].path = word_path\n",
    "        # 把节点计算得到的霍夫曼码、路径  写入词典的数值中\n",
    "        wordid_code[word_id] = word_code\n",
    "        wordid_path[word_id] = word_path\n",
    "    return wordid_code, wordid_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordid_code, wordid_path = generate_huffman_code_and_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/huffman_tree.png\"  width=\"700\" height=\"700\" align=\"bottom\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [1, 1], 0: [1, 0], 3: [0, 1, 1], 4: [0, 1, 0], 2: [0, 0]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordid_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_pos_and_neg_path():\n",
    "    positive = []  # 所有词的正向路径数组\n",
    "    negative = []  # 所有词的负向路径数组\n",
    "    for word_id in range(len(wordid_frequency_dict)):\n",
    "        pos_id = []  # 存放一个词 路径中的正向节点id\n",
    "        neg_id = []  # 存放一个词 路径中的负向节点id\n",
    "        for i, code in enumerate(huffman[word_id].Huffman_code):\n",
    "            if code == 1:\n",
    "                pos_id.append(huffman[word_id].path[i])\n",
    "            else:\n",
    "                neg_id.append(huffman[word_id].path[i])\n",
    "        positive.append(pos_id)\n",
    "        negative.append(neg_id)\n",
    "    return positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive, negative = get_all_pos_and_neg_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8], [8, 7], [], [6, 5], [6]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7], [], [8, 6], [8], [8, 5]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
